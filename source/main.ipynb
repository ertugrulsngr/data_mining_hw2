{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder_name = \"DM_dataset_hw2\"\n",
    "dataset_file_name = \"fake_news_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "dataset_path = os.path.join(ws_path, dataset_folder_name, dataset_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>@POTUS Biden Blunders - 6 Month Update\\n\\nInfl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>@S0SickRick @Stairmaster_ @6d6f636869 Not as m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>THE SUPREME COURT is siding with super rich pr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>@POTUS Biden Blunders\\n\\nBroken campaign promi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>@OhComfy I agree. The confluence of events rig...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134193</th>\n",
       "      <td>False</td>\n",
       "      <td>Joe Biden's family owned African slaves....\\n\\...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134194</th>\n",
       "      <td>False</td>\n",
       "      <td>Joe Bidens great, great grandfather was a slav...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134195</th>\n",
       "      <td>False</td>\n",
       "      <td>@ChevyChaseToGo \"Joe Bidens great-grandfather ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134196</th>\n",
       "      <td>False</td>\n",
       "      <td>@JoeBiden Facts are Bidens VP Kamala Harris Gr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134197</th>\n",
       "      <td>False</td>\n",
       "      <td>@sunny Yes representation matters. Did you kno...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134198 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                              tweet  score\n",
       "0         True  @POTUS Biden Blunders - 6 Month Update\\n\\nInfl...      5\n",
       "1         True  @S0SickRick @Stairmaster_ @6d6f636869 Not as m...      3\n",
       "2         True  THE SUPREME COURT is siding with super rich pr...      4\n",
       "3         True  @POTUS Biden Blunders\\n\\nBroken campaign promi...      5\n",
       "4         True  @OhComfy I agree. The confluence of events rig...      4\n",
       "...        ...                                                ...    ...\n",
       "134193   False  Joe Biden's family owned African slaves....\\n\\...      5\n",
       "134194   False  Joe Bidens great, great grandfather was a slav...      4\n",
       "134195   False  @ChevyChaseToGo \"Joe Bidens great-grandfather ...      5\n",
       "134196   False  @JoeBiden Facts are Bidens VP Kamala Harris Gr...      3\n",
       "134197   False  @sunny Yes representation matters. Did you kno...      4\n",
       "\n",
       "[134198 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null check\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(model, X_train, X_test, y_train, y_test):\n",
    "    train_start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Train time: \", time() - train_start)\n",
    "    test_start = time()\n",
    "    prediction = model.predict(X_test)\n",
    "    print(\"Test time: \", time() - test_start)\n",
    "    print(classification_report(prediction, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(dataset[\"tweet\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<134198x169270 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2504114 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.03248858451843262\n",
      "Test time:  79.83325672149658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97     12543\n",
      "        True       0.99      0.95      0.97     14297\n",
      "\n",
      "    accuracy                           0.97     26840\n",
      "   macro avg       0.97      0.97      0.97     26840\n",
      "weighted avg       0.97      0.97      0.97     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "display_scores(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  76.22720861434937\n",
      "Test time:  0.032271623611450195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98     13079\n",
      "        True       0.98      0.98      0.98     13761\n",
      "\n",
      "    accuracy                           0.98     26840\n",
      "   macro avg       0.98      0.98      0.98     26840\n",
      "weighted avg       0.98      0.98      0.98     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "display_scores(dc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.06399273872375488\n",
      "Test time:  0.012064933776855469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.96      0.95     12728\n",
      "        True       0.96      0.94      0.95     14112\n",
      "\n",
      "    accuracy                           0.95     26840\n",
      "   macro avg       0.95      0.95      0.95     26840\n",
      "weighted avg       0.95      0.95      0.95     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "display_scores(nb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=2000)\n",
    "X = vectorizer.fit_transform(dataset[\"tweet\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<134198x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1684751 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.018564224243164062\n",
      "Test time:  86.1012933254242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.99      0.82      9178\n",
      "        True       1.00      0.78      0.87     17662\n",
      "\n",
      "    accuracy                           0.85     26840\n",
      "   macro avg       0.85      0.88      0.85     26840\n",
      "weighted avg       0.89      0.85      0.85     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "display_scores(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  39.396164417266846\n",
      "Test time:  0.027048349380493164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.97      0.97     12991\n",
      "        True       0.97      0.97      0.97     13849\n",
      "\n",
      "    accuracy                           0.97     26840\n",
      "   macro avg       0.97      0.97      0.97     26840\n",
      "weighted avg       0.97      0.97      0.97     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "display_scores(dc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.035776615142822266\n",
      "Test time:  0.0049402713775634766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.95      0.93     12673\n",
      "        True       0.95      0.92      0.94     14167\n",
      "\n",
      "    accuracy                           0.94     26840\n",
      "   macro avg       0.93      0.94      0.94     26840\n",
      "weighted avg       0.94      0.94      0.94     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "display_scores(nb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(dataset[\"tweet\"])\n",
    "svd = TruncatedSVD(n_components=1000, random_state=42)\n",
    "X = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134198, 1000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.04211544990539551\n",
      "Test time:  56.516252517700195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.99      0.82      9178\n",
      "        True       1.00      0.78      0.87     17662\n",
      "\n",
      "    accuracy                           0.85     26840\n",
      "   macro avg       0.85      0.88      0.85     26840\n",
      "weighted avg       0.89      0.85      0.85     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "display_scores(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  37.894444942474365\n",
      "Test time:  0.02352142333984375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.97      0.97     12996\n",
      "        True       0.97      0.97      0.97     13844\n",
      "\n",
      "    accuracy                           0.97     26840\n",
      "   macro avg       0.97      0.97      0.97     26840\n",
      "weighted avg       0.97      0.97      0.97     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "display_scores(dc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.022018909454345703\n",
      "Test time:  0.0049817562103271484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.95      0.93     12673\n",
      "        True       0.95      0.92      0.94     14167\n",
      "\n",
      "    accuracy                           0.94     26840\n",
      "   macro avg       0.93      0.94      0.94     26840\n",
      "weighted avg       0.94      0.94      0.94     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "display_scores(nb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(dataset[\"tweet\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<134198x3265511 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7422383 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.042620182037353516\n",
      "Test time:  80.97906064987183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.99      0.96     12349\n",
      "        True       0.99      0.94      0.96     14491\n",
      "\n",
      "    accuracy                           0.96     26840\n",
      "   macro avg       0.96      0.96      0.96     26840\n",
      "weighted avg       0.96      0.96      0.96     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "display_scores(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  1046.8513236045837\n",
      "Test time:  0.09778380393981934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98     13055\n",
      "        True       0.98      0.98      0.98     13785\n",
      "\n",
      "    accuracy                           0.98     26840\n",
      "   macro avg       0.98      0.98      0.98     26840\n",
      "weighted avg       0.98      0.98      0.98     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "display_scores(dc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.40999269485473633\n",
      "Test time:  0.07758069038391113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.98      0.97     12788\n",
      "        True       0.99      0.97      0.98     14052\n",
      "\n",
      "    accuracy                           0.97     26840\n",
      "   macro avg       0.97      0.97      0.97     26840\n",
      "weighted avg       0.97      0.97      0.97     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "display_scores(nb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=2000)\n",
    "X = vectorizer.fit_transform(dataset[\"tweet\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<134198x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1770041 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.02704167366027832\n",
      "Test time:  66.8125422000885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.99      0.86     10059\n",
      "        True       0.99      0.82      0.90     16781\n",
      "\n",
      "    accuracy                           0.88     26840\n",
      "   macro avg       0.88      0.90      0.88     26840\n",
      "weighted avg       0.91      0.88      0.88     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "display_scores(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  44.02996802330017\n",
      "Test time:  0.04000425338745117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.97      0.97     13015\n",
      "        True       0.97      0.97      0.97     13825\n",
      "\n",
      "    accuracy                           0.97     26840\n",
      "   macro avg       0.97      0.97      0.97     26840\n",
      "weighted avg       0.97      0.97      0.97     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "display_scores(dc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  0.03705430030822754\n",
      "Test time:  0.002951383590698242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.95      0.94     12735\n",
      "        True       0.95      0.93      0.94     14105\n",
      "\n",
      "    accuracy                           0.94     26840\n",
      "   macro avg       0.94      0.94      0.94     26840\n",
      "weighted avg       0.94      0.94      0.94     26840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "display_scores(nb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(X)\n",
      "File \u001b[1;32mc:\\Users\\ertug\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2078\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2072\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2073\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2074\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2075\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2076\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2077\u001b[0m )\n\u001b[1;32m-> 2078\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2081\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ertug\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1359\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_words_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limit_features(\n\u001b[0;32m   1356\u001b[0m         X, vocabulary, max_doc_count, min_doc_count, max_features\n\u001b[0;32m   1357\u001b[0m     )\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1359\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_ \u001b[38;5;241m=\u001b[39m vocabulary\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\ertug\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1146\u001b[0m, in \u001b[0;36mCountVectorizer._sort_features\u001b[1;34m(self, X, vocabulary)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_val, (term, old_val) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorted_features):\n\u001b[0;32m   1145\u001b[0m     vocabulary[term] \u001b[38;5;241m=\u001b[39m new_val\n\u001b[1;32m-> 1146\u001b[0m     map_index[old_val] \u001b[38;5;241m=\u001b[39m new_val\n\u001b[0;32m   1148\u001b[0m X\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m map_index\u001b[38;5;241m.\u001b[39mtake(X\u001b[38;5;241m.\u001b[39mindices, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(dataset[\"tweet\"])\n",
    "svd = TruncatedSVD(n_components=1000, random_state=42)\n",
    "X = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "display_scores(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "display_scores(dc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "display_scores(nb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
